{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO v11së¥¼ ì´ìš©í•œ ê°œ ê°ì²´ íƒì§€ í›„ 224x224ë¡œ ë¦¬ì‚¬ì´ì¦ˆí•˜ê³  ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
    "ìšœë¡œëŠ” COCO ë°ì´í„°ì…‹ì˜ 80ê°œì˜ í´ë˜ìŠ¤ë¥¼ ê°€ì§€ê³  ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ì…ë‹ˆë‹¤.\n",
    "80ê°œì˜ í´ë˜ìŠ¤ ì¤‘ì— 16ë²ˆ ì¸ë±ìŠ¤(ìˆ«ìë¡œ ì„¸ë©´ 17ë²ˆì¨°)ì´ ê°œ í´ë˜ìŠ¤ì¸ë° ì¶œì²˜ì— ë”°ë¼ ì¸ë±ìŠ¤ 17ì´ë¼ê³  ì¡°ê¸ˆ ë‹¤ë¥´ê²Œ ë‚˜ì˜µë‹ˆë‹¤.\n",
    "ì¼ë‹¨ ì‘ë™í•´ì„œ 16ìœ¼ë¡œ ë‘ì—ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… YOLOv11 ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "Using device: mps\n",
      "âœ… ResNetëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "\n",
      "0: 416x640 1 dog, 60.5ms\n",
      "Speed: 0.9ms preprocess, 60.5ms inference, 0.3ms postprocess per image at shape (1, 3, 416, 640)\n",
      "ğŸ” ê²€ì¶œëœ ê°ì²´ë“¤:\n",
      "  í´ë˜ìŠ¤: 16, ì‹ ë¢°ë„: 0.95\n",
      "âœ… ì˜ˆì¸¡ëœ í¬ì¦ˆ: SIT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ëª¨ë¸, ìšœë¡œ, ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì •ë§Œ í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.\n",
    "# ------------------------\n",
    "# 1. YOLOv11 ëª¨ë¸ ë¡œë“œ (ê°œ ê°ì²´ íƒì§€ìš©)\n",
    "# ------------------------\n",
    "# YOLOv11s ëª¨ë¸ì€ COCO ë°ì´í„°ì…‹ìœ¼ë¡œ ì‚¬ì „ í•™ìŠµë˜ì–´ ìˆìœ¼ë¯€ë¡œ, 'dog' í´ë˜ìŠ¤(ì¼ë°˜ì ìœ¼ë¡œ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ 16)ë¥¼ ì¸ì‹í•©ë‹ˆë‹¤.\n",
    "yolo_model_path = \"/Users/vairocana/Downloads/yolo11m.pt\"  # YOLOv11s ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (í•´ë‹¹ íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•¨)\n",
    "yolo_model = YOLO(yolo_model_path)\n",
    "print(\"âœ… YOLOv11 ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# ------------------------\n",
    "# 2. ResNet ëª¨ë¸ ë¡œë“œ (ë¶„ë¥˜ìš©)\n",
    "# ------------------------\n",
    "model_path = \"/Users/vairocana/Desktop/AI/resnet_models/resnet18_model_82.pth\"  # ì €ì¥ëœ ResNet50 ëª¨ë¸ íŒŒì¼ ê²½ë¡œ\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ResNet50 ëª¨ë¸ì„ ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì—†ì´ ìƒì„±í•œ í›„, ë§ˆì§€ë§‰ fc ë ˆì´ì–´ë¥¼ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ìˆ˜ì— ë§ê²Œ ìˆ˜ì •\n",
    "model = models.resnet18(weights=None)\n",
    "num_features = model.fc.in_features\n",
    "num_classes = 10  # í´ë˜ìŠ¤ ê°œìˆ˜ (ë°ì´í„°ì…‹ì— ë§ê²Œ ìˆ˜ì •)\n",
    "model.fc = nn.Linear(num_features, num_classes)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì „í™˜ (Dropout, BatchNorm ë“± ë¹„í™œì„±í™”)\n",
    "print(\"âœ… ResNetëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# ------------------------\n",
    "# 3. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜ (224Ã—224, ì •ê·œí™”)\n",
    "# ------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # í¬ë¡­ëœ ì´ë¯¸ì§€ë¥¼ 224Ã—224ë¡œ ì¡°ì •\n",
    "    transforms.ToTensor(),  # í…ì„œ ë³€í™˜\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet ì •ê·œí™”\n",
    "])\n",
    "\n",
    "# ------------------------\n",
    "# 4. YOLOë¥¼ ì´ìš©í•˜ì—¬ \"dog\" ê°ì²´ë¥¼ íƒì§€í•˜ê³  í¬ë¡­í•˜ëŠ” í•¨ìˆ˜\n",
    "# ------------------------\n",
    "def detect_and_crop(image_path):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ ì´ë¯¸ì§€ ê²½ë¡œì—ì„œ YOLOv8ì„ ì´ìš©í•´ 'dog' ê°ì²´(í´ë˜ìŠ¤ ì¸ë±ìŠ¤ 16)ë¥¼ íƒì§€í•˜ê³ ,\n",
    "    í•´ë‹¹ ë°”ìš´ë”© ë°•ìŠ¤ ì˜ì—­ì„ í¬ë¡­í•œ í›„ 224Ã—224ë¡œ ì „ì²˜ë¦¬í•œ ì´ë¯¸ì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # ì´ë¯¸ì§€ ë¡œë“œ ë° BGR -> RGB ë³€í™˜ (YOLOëŠ” RGB ì‚¬ìš©)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}\")\n",
    "        return None\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # YOLO ì¶”ë¡  ìˆ˜í–‰\n",
    "    results = yolo_model(image_rgb)\n",
    "\n",
    "    # ë””ë²„ê·¸: íƒì§€ëœ ëª¨ë“  ê°ì²´ ì •ë³´ ì¶œë ¥\n",
    "    print(\"ğŸ” ê²€ì¶œëœ ê°ì²´ë“¤:\")\n",
    "    for result in results:\n",
    "        for box in result.boxes.data:\n",
    "            # YOLOv11 ê²°ê³¼ tensorë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ [x1, y1, x2, y2, confidence, class] ìˆœì„œë¡œ ì–»ìŒ\n",
    "            box_vals = box.tolist()\n",
    "            x1, y1, x2, y2, conf, cls = box_vals\n",
    "            print(f\"  í´ë˜ìŠ¤: {int(cls)}, ì‹ ë¢°ë„: {conf:.2f}\")\n",
    "\n",
    "    # 'dog' ê°ì²´ ì¶”ì¶œ (COCO ê¸°ì¤€ dog í´ë˜ìŠ¤ ì¸ë±ìŠ¤ëŠ” ì¼ë°˜ì ìœ¼ë¡œ 16)\n",
    "    found_dog = False\n",
    "    for result in results:\n",
    "        for box in result.boxes.data:\n",
    "            box_vals = box.tolist()\n",
    "            x1, y1, x2, y2, conf, cls = box_vals\n",
    "            # ì—¬ê¸°ì„œ dog í´ë˜ìŠ¤ ì¡°ê±´: í´ë˜ìŠ¤ ì¸ë±ìŠ¤ 16, ì‹ ë¢°ë„ 0.4 ì´ìƒ (í•„ìš”ì— ë”°ë¼ ì¡°ì •)\n",
    "            if int(cls) == 16 and conf > 0.4:\n",
    "                found_dog = True\n",
    "                # ì¢Œí‘œ ì •ìˆ˜í˜• ë³€í™˜\n",
    "                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "                # ê°œ ê°ì²´ ì˜ì—­ í¬ë¡­ (RGB ì´ë¯¸ì§€ ê¸°ì¤€)\n",
    "                cropped_img = image_rgb[y1:y2, x1:x2]\n",
    "                # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜\n",
    "                cropped_img_pil = Image.fromarray(cropped_img)\n",
    "                # ì „ì²˜ë¦¬: 224Ã—224 ë¦¬ì‚¬ì´ì¦ˆ ë° ì •ê·œí™”, ë°°ì¹˜ ì°¨ì› ì¶”ê°€\n",
    "                processed_img = transform(cropped_img_pil)\n",
    "                processed_img = processed_img.unsqueeze(0)\n",
    "                return processed_img.to(device)\n",
    "    if not found_dog:\n",
    "        print(\"âš ï¸ ì´ë¯¸ì§€ì—ì„œ ê°œ ê°ì²´ë¥¼ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!\")\n",
    "    return None\n",
    "\n",
    "# ------------------------\n",
    "# 5. ResNetì„ ì´ìš©í•˜ì—¬ í¬ì¦ˆ(í´ë˜ìŠ¤) ë¶„ë¥˜í•˜ëŠ” í•¨ìˆ˜\n",
    "# ------------------------\n",
    "def classify_pose(image_path):\n",
    "    \"\"\"\n",
    "    YOLOë¥¼ ì‚¬ìš©í•´ ì£¼ì–´ì§„ ì´ë¯¸ì§€ì—ì„œ ê°œ ê°ì²´ë¥¼ íƒì§€í•˜ì—¬ í¬ë¡­í•œ í›„,\n",
    "    ResNet ëª¨ë¸ë¡œ ë¶„ë¥˜í•˜ì—¬ í¬ì¦ˆ(í´ë˜ìŠ¤)ë¥¼ ì˜ˆì¸¡í•˜ëŠ” í•¨ìˆ˜.\n",
    "    \"\"\"\n",
    "    cropped_image = detect_and_crop(image_path)\n",
    "    if cropped_image is None:\n",
    "        print(\"âŒ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ê°œ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    # ResNet50ì„ ì´ìš©í•œ ì˜ˆì¸¡ (gradient ê³„ì‚° ë¹„í™œì„±í™”)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(cropped_image)\n",
    "        _, predicted_class = outputs.max(1)\n",
    "\n",
    "    # í´ë˜ìŠ¤ ë¼ë²¨ (ë°ì´í„°ì…‹ì— ë§ê²Œ ìˆ˜ì •)\n",
    "    class_labels = [\n",
    "        \"BODYLOWER\", \"BODYSCRATCH\", \"BODYSHAKE\", \"FEETUP\", \n",
    "        \"FOOTUP\", \"LYING\", \"MOUNTING\", \"SIT\", \"TURN\", \"WALKRUN\"\n",
    "    ]\n",
    "    predicted_label = class_labels[predicted_class.item()]\n",
    "    print(f\"âœ… ì˜ˆì¸¡ëœ í¬ì¦ˆ: {predicted_label}\")\n",
    "\n",
    "# ------------------------\n",
    "# 6. ì‹¤í–‰: ë‹¨ì¼ ì´ë¯¸ì§€ì— ëŒ€í•´ YOLOë¡œ ê°œ ê°ì²´ íƒì§€ í›„, ResNetìœ¼ë¡œ ë¶„ë¥˜\n",
    "# ------------------------\n",
    "image_path = \"/Users/vairocana/Downloads/sample7.jpeg\"  # í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œ (ìˆ˜ì • í•„ìš”)\n",
    "classify_pose(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ìšœë¡œë¡œ í¬ë¡­ëœ ì´ë¯¸ì§€ í™•ì¸ì„ ìœ„í•œ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… YOLOv11 ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "\n",
      "0: 640x512 2 dogs, 1 skis, 46.3ms\n",
      "Speed: 1.3ms preprocess, 46.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "ğŸ” ê²€ì¶œëœ ê°ì²´ë“¤:\n",
      "  í´ë˜ìŠ¤: 16, ì‹ ë¢°ë„: 0.81\n",
      "  í´ë˜ìŠ¤: 16, ì‹ ë¢°ë„: 0.36\n",
      "  í´ë˜ìŠ¤: 30, ì‹ ë¢°ë„: 0.33\n",
      "âœ… ê°œ ê°ì²´ë¥¼ ê²€ì¶œí•˜ì—¬ í¬ë¡­í–ˆìŠµë‹ˆë‹¤! ì €ì¥ ê²½ë¡œ: /Users/vairocana/Downloads//cropped_dog.jpg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "#ìšœë¡œì™€ ì´ë¯¸ì§€ ê²½ë¡œë§Œ ìˆ˜ì •í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.\n",
    "# ------------------------\n",
    "# 1. YOLOv11 ëª¨ë¸ ë¡œë“œ \n",
    "# ------------------------\n",
    "yolo_model_path = \"/Users/vairocana/Downloads/yolo11s.pt\"  # YOLOv11s ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (í•´ë‹¹ íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•¨)\n",
    "yolo_model = YOLO(yolo_model_path)\n",
    "print(\"âœ… YOLOv11 ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# ------------------------\n",
    "# 2. ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì • (í•„ìš”ì— ë”°ë¼ ìˆ˜ì •)\n",
    "# ------------------------\n",
    "image_path = \"/Users/vairocana/Downloads/coco_sample2.jpg\"\n",
    "output_path = \"/Users/vairocana/Downloads//cropped_dog.jpg\"\n",
    "\n",
    "# ------------------------\n",
    "# 3. ì´ë¯¸ì§€ ë¡œë“œ ë° YOLO ì¶”ë¡  ìˆ˜í–‰\n",
    "# ------------------------\n",
    "image = cv2.imread(image_path)\n",
    "if image is None:\n",
    "    print(f\"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}\")\n",
    "    exit()\n",
    "\n",
    "# OpenCVëŠ” BGR, YOLOëŠ” RGBì´ë¯€ë¡œ ë³€í™˜\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "results = yolo_model(image_rgb)  # YOLO ì¶”ë¡  ìˆ˜í–‰\n",
    "\n",
    "# ------------------------\n",
    "# 4. ë””ë²„ê¹…: ê²€ì¶œëœ ëª¨ë“  ê°ì²´ ì •ë³´ ì¶œë ¥\n",
    "# ------------------------\n",
    "print(\"ğŸ” ê²€ì¶œëœ ê°ì²´ë“¤:\")\n",
    "for result in results:\n",
    "    # result.boxes.dataëŠ” ê° ë°•ìŠ¤ì— ëŒ€í•´ [x1, y1, x2, y2, confidence, class]ë¥¼ í¬í•¨í•˜ëŠ” tensorì…ë‹ˆë‹¤.\n",
    "    for box in result.boxes.data:\n",
    "        # í…ì„œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì¸ë±ìŠ¤ë¡œ ì ‘ê·¼\n",
    "        box = box.tolist()\n",
    "        x1, y1, x2, y2, conf, cls = box\n",
    "        print(f\"  í´ë˜ìŠ¤: {int(cls)}, ì‹ ë¢°ë„: {conf:.2f}\")\n",
    "\n",
    "# ------------------------\n",
    "# 5. \"dog\" í´ë˜ìŠ¤ (COCO ê¸°ì¤€ dogì˜ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ëŠ” 16ì´ë¼ê³  ë‚˜ì˜¨ê³³ë„ ìˆê³  17ë„ ìˆìŒ..)ë§Œ ì¶”ì¶œí•˜ì—¬ í¬ë¡­\n",
    "# ------------------------\n",
    "found_dog = False\n",
    "for result in results:\n",
    "    for box in result.boxes.data:\n",
    "        box = box.tolist()\n",
    "        x1, y1, x2, y2, conf, cls = box\n",
    "        if int(cls) == 16 and conf > 0.4:  # dog í´ë˜ìŠ¤ ì¸ë±ìŠ¤ê°€ 16 ì•„ë‹ˆë©´ 17ì¸ë° ì°¾ì•„ë„ ë‘˜ë‹¤ ë‚˜ì™€ì„œ ì¼ë‹¨ 16ìœ¼ë¡œ ì„¤ì •. ì¡°ê±´ (ì‹ ë¢°ë„ 0.4 ì´ìƒ)\n",
    "            found_dog = True\n",
    "            # ì¢Œí‘œ ì •ìˆ˜í˜• ë³€í™˜\n",
    "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "            # ê°œ ê°ì²´ ì˜ì—­ í¬ë¡­ (RGB ì´ë¯¸ì§€ ê¸°ì¤€)\n",
    "            cropped_dog = image_rgb[y1:y2, x1:x2]\n",
    "            # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜ í›„ ì €ì¥ (JPEG í’ˆì§ˆ 95)\n",
    "            cropped_img_pil = Image.fromarray(cropped_dog)\n",
    "            cropped_img_pil.save(output_path, quality=95)\n",
    "            print(f\"âœ… ê°œ ê°ì²´ë¥¼ ê²€ì¶œí•˜ì—¬ í¬ë¡­í–ˆìŠµë‹ˆë‹¤! ì €ì¥ ê²½ë¡œ: {output_path}\")\n",
    "            break  # í•˜ë‚˜ì˜ ê°œë§Œ ì²˜ë¦¬\n",
    "    if found_dog:\n",
    "        break\n",
    "\n",
    "if not found_dog:\n",
    "    print(\"âŒ ì´ë¯¸ì§€ì—ì„œ ê°œ ê°ì²´ë¥¼ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
