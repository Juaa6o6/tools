{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO + ResNet íŒŒì´í”„ë¼ì¸ ì„¤ëª… (.GIF (or MP4) ì²˜ë¦¬ ì„¤ëª…ì€ X)\n",
    "\n",
    "ì´ íŒŒì´í”„ë¼ì¸ì€ ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ íŒŒì¼(ì„ì‹œì )ì—ì„œ 0.1ì´ˆ ë‹¹ 1ê°œ ì´ë¯¸ì§€ ìº¡ì²˜ í›„,  \n",
    "YOLO ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ê°œ ê°ì²´ë¥¼ íƒì§€í•œ í›„, í•´ë‹¹ ê°œì˜ ì´ë¯¸ì§€ë¥¼ ResNet ëª¨ë¸ë¡œ ì…ë ¥í•˜ì—¬  \n",
    "í–‰ë™ì„ ì˜ˆì¸¡í•˜ê³  ë¡œê·¸ë¡œ ì €ì¥í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.  \n",
    "\n",
    "íŒŒì¼ ë° í´ë” êµ¬ì¡°\n",
    "- `ROGUN/`\n",
    "  - `screenshot/` : YOLO ì ìš© ì „ ì›ë³¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥\n",
    "  - `bbox_screenshot/` : YOLOë¥¼ í†µí•´ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ í‘œì‹œí•œ ì´ë¯¸ì§€ ì €ì¥\n",
    "  - `log.csv` : íƒ€ì„ìŠ¤íƒ¬í”„, ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ, ì˜ˆì¸¡ëœ í–‰ë™ í´ë˜ìŠ¤ ì €ì¥\n",
    "\n",
    "> ì´ í´ë”ì™€ íŒŒì¼ë“¤ì€ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤\n",
    "\n",
    "---\n",
    "\n",
    "íŒŒì´í”„ë¼ì¸ ë™ì‘ ì›ë¦¬\n",
    "\n",
    "1. ì‹¤ì‹œê°„ í”„ë ˆì„ ìº¡ì²˜\n",
    "- OpenCVë¥¼ ì‚¬ìš©í•˜ì—¬ 0.1ì´ˆë§ˆë‹¤ í”„ë ˆì„ì„ ìº¡ì²˜.\n",
    "- `screenshot/` í´ë”ì— ì›ë³¸ í”„ë ˆì„ì„ ì €ì¥.\n",
    "\n",
    "2. YOLOë¥¼ ì´ìš©í•œ ê°œ ê°ì§€\n",
    "- YOLO ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê°œ ê°ì²´ë§Œ íƒì§€.\n",
    "- ê°œê°€ ì—¬ëŸ¬ ë§ˆë¦¬ ê°ì§€ë  ê²½ìš°, ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ë¥¼ ê°€ì§„ ê°œ í•œ ë§ˆë¦¬ë¥¼ ì„ íƒ.\n",
    "\n",
    "3. ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë¦° ì´ë¯¸ì§€ ì €ì¥\n",
    "- ê°œê°€ ê°ì§€ëœ ê²½ìš°, ì›ë³¸ ì´ë¯¸ì§€ ìœ„ì— ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë¦° í›„ `bbox_screenshot/` í´ë”ì— ì €ì¥.\n",
    "- ë‚˜ì¤‘ì— .gif ë§Œë“œëŠ”ë° ì‚¬ìš©.\n",
    "\n",
    "4. ResNetì„ í™œìš©í•œ í–‰ë™ ë¶„ë¥˜\n",
    "- YOLOë¡œ ê°ì§€ëœ ê°œì˜ ì´ë¯¸ì§€ë¥¼ í¬ë¡­í•˜ì—¬ ResNet ëª¨ë¸ì— ì…ë ¥.\n",
    "- í¬ë¡­ëœ ì´ë¯¸ì§€ëŠ” ë”°ë¡œ ì €ì¥ ì•ˆë˜ê³  ë©”ëª¨ë¦¬ì—ì„œ ë°”ë¡œ ë„˜ì–´ì˜´.\n",
    "- ResNet ëª¨ë¸ì€ 10ê°€ì§€ í–‰ë™ í´ë˜ìŠ¤ ì¤‘ ì˜ˆì¸¡.\n",
    "\n",
    "5. ì˜ˆì¸¡ ê²°ê³¼ë¥¼ CSV ë¡œê·¸ì— ì €ì¥\n",
    "- `log.csv` íŒŒì¼ì— íƒ€ì„ìŠ¤íƒ¬í”„, ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ, ì˜ˆì¸¡ëœ í–‰ë™ í´ë˜ìŠ¤ë¥¼ ì €ì¥í•œë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì˜ˆì‹œ\n",
    "\n",
    "ê°œê°€ ê°ì§€ëœ ê²½ìš°\n",
    "- ìŠ¤í¬ë¦°ìƒ· ì €ì¥: `ROGUN/screenshot/20250222-143050.jpg`\n",
    "- ê°œ ê°ì§€ë¨ (ì¢Œí‘œ: (120, 80, 250, 220), ì‹ ë¢°ë„: 0.85)\n",
    "- ë°”ìš´ë”© ë°•ìŠ¤ ì´ë¯¸ì§€ ì €ì¥: `ROGUN/bbox_screenshot/20250222-143050_bbox.jpg`\n",
    "- ì˜ˆì¸¡ëœ í¬ì¦ˆ: WALKRUN (í™•ë¥ : 0.92)\n",
    "- ë¡œê·¸ ì €ì¥ ì™„ë£Œ: `ROGUN/log.csv`\n",
    "\n",
    "í™œìš© ì˜ˆì‹œ\n",
    "\n",
    "- ë¹„ë””ì˜¤ íŒŒì¼ ë¶„ì„\n",
    "  - `video_path = \"/path/to/video.mp4\"` (ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ì„¤ì •)\n",
    "- YOLO v11 ì‚¬ìš© \n",
    "  - `yolo_model = YOLO(\"yolov11m.pt\")` \n",
    "  - ì†ë„ê°€ ëŠë¦¬ë©´ ë” ë¹ ë¥¸ ìšœë¡œ ëª¨ë¸ë¡œ ë³€ê²½ ê°€ëŠ¥ \n",
    "- **ResNet18 â†’ ResNet50 ë³€ê²½ ê°€ëŠ¥**\n",
    "  - `resnet_model = models.resnet50(weights=None)`\n",
    "\n",
    "---\n",
    "\n",
    "ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­\n",
    "- Python 3.8 ì´ìƒ\n",
    "- PyTorch, OpenCV, PIL, Pandas, Ultralytics (YOLO)\n",
    "- Apple MPS (Mac) ë˜ëŠ” CUDA (Windows/Linux)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ì˜ìƒì—ì„œ ìŠ¤í¬ë¦°ìƒ· ì €ì¥, bbox ìŠ¤í¬ë¦°ìƒ· ì €ì¥, csv ë¡œê·¸ ì €ì¥ í•˜ëŠ” ì½”ë“œê³  ì‹¤ì‹œê°„ ì˜ìƒ ì²˜ë¦¬í•˜ëŠ” ì½”ë“œëŠ” ì•„ë‹™ë‹ˆë‹¤.\n",
    "#.MP4 íŒŒì¼ ë§Œë“¤ì–´ì£¼ëŠ” ì½”ë“œ ë‹¤ìŒ ì½”ë“œì— ìˆìŠµë‹ˆë‹¤. .GIF ë³´ë‹¤ .MP4 íŒŒì¼ì´ ë” í¬ê¸°ê°€ ì‘ì•„ì„œ ì¼ë‹¨ .MP4ë¡œ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤(ì‰½ê²Œ .GIFë¡œ ë³€ê²½ê°€ëŠ¥).\n",
    "#GIF ë˜ëŠ” MP4 íŒŒì¼ì´ ìƒê°ë³´ë‹¤ ê³ ë ¤í• ê²Œ ë§ì•„ì„œ ë‹¤ìŒ ì½”ë“œ ì°¸ê³ í•˜ì‹œê³  ê¸°ëŠ¥ ìœ ì§€í• ì§€ ê³ ì³ ì‚¬ìš©í• ì§€ëŠ” ì—¬ëŸ¬ë¶„ ë§ˆìŒì…ë‹ˆë‹¤. ì €ëŠ” ë‘˜ë‹¤ ì°¬ì„±ì…ë‹ˆë‹¤.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "\n",
    "# ------------------------\n",
    "# 1. í™˜ê²½ ì„¤ì •\n",
    "# ------------------------\n",
    "video_path = \"/Users/vairocana/Downloads/test_video1.mp4\"  # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì„ ì‚¬ìš©í•  ê²½ìš°, 0ìœ¼ë¡œ ì„¤ì • (video_path = 0). ê²½ë¡œëŠ” í•„ìš”ì‹œ ë³€ê²½\n",
    "output_dir = \"/Users/vairocana/Downloads/ROGUN\"  # ì €ì¥í•  í´ë”\n",
    "screenshot_dir = os.path.join(output_dir, \"screenshot\")  # ì›ë³¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥ í´ë”\n",
    "bbox_screenshot_dir = os.path.join(output_dir, \"bbox_screenshot\")  # ë°”ìš´ë”© ë°•ìŠ¤ ìŠ¤í¬ë¦°ìƒ· ì €ì¥ í´ë”\n",
    "log_csv_path = os.path.join(output_dir, \"log.csv\")  # CSV ë¡œê·¸ ê²½ë¡œ\n",
    "\n",
    "# í´ë” ìƒì„± (ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìë™ ìƒì„±)\n",
    "os.makedirs(screenshot_dir, exist_ok=True)\n",
    "os.makedirs(bbox_screenshot_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# CSV ë¡œê·¸ ì´ˆê¸°í™” (ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)\n",
    "columns = [\"timestamp\", \"bbox\", \"class\"]\n",
    "log_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# ------------------------\n",
    "# 2. YOLOv11 ëª¨ë¸ ë¡œë“œ (ê°œ ê°ì²´ íƒì§€) ***ìšœë¡œ ëª¨ë¸ì€ ì§ì ‘ ë‹¤ìš´ ë°›ê³  ê²½ë¡œ ì„¤ì •í•´ì•¼í•¨***\n",
    "# ------------------------\n",
    "yolo_model = YOLO(\"/Users/vairocana/Downloads/yolo11m.pt\")  #YOLOv11m ì‚¬ìš©. ëŠë¦¬ë©´ 11s, 11n ì‚¬ìš©.\n",
    "print(\"âœ… YOLO ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# ------------------------\n",
    "# 3. ResNet ëª¨ë¸ ë¡œë“œ (í¬ì¦ˆ ë¶„ë¥˜) ***í•™ìŠµì‹œí‚¨ ëª¨ë¸ì´ resnet50ì´ë¼ë©´ resnet50ìœ¼ë¡œ ë³€ê²½***\n",
    "# ------------------------\n",
    "resnet_model = models.resnet18(weights=None) #í•„ìš”ì‹œ ë³€ê²½\n",
    "num_features = resnet_model.fc.in_features\n",
    "num_classes = 10  # í˜„ì¬ 10ê°œ í´ë˜ìŠ¤ ì‚¬ìš©. 8ê°œ í´ë˜ìŠ¤ ëª¨ë¸ì´ë©´ ë°”ê¿”ì•¼ í•¨.\n",
    "resnet_model.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "# í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "model_path = \"/Users/vairocana/Desktop/AI/resnet_models/resnet18_model_82.pth\" #ê²½ë¡œëŠ” ê°ì ì„¤ì •\n",
    "resnet_model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "resnet_model.to(\"cpu\")\n",
    "resnet_model.eval()  # í‰ê°€ ëª¨ë“œ (Dropout, BatchNorm ë¹„í™œì„±í™”)\n",
    "print(\"âœ… ResNet ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# ------------------------\n",
    "# 4. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ (ResNet ì…ë ¥ì— ë§ê²Œ ë³€í™˜)\n",
    "# ------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 224x224 í¬ê¸°ë¡œ ì¡°ì •\n",
    "    transforms.ToTensor(),  # PyTorch í…ì„œ ë³€í™˜\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet ì •ê·œí™”\n",
    "])\n",
    "\n",
    "# ------------------------\n",
    "# 5. ì‹¤ì‹œê°„ ì˜ìƒ ì²˜ë¦¬ (YOLO â†’ ResNet + ì´ë¯¸ì§€ ì €ì¥)\n",
    "# ------------------------\n",
    "def process_video():\n",
    "    global log_df  # CSV ë¡œê·¸ ë°ì´í„°í”„ë ˆì„\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)  # OpenCVë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì—´ê¸°\n",
    "    if not cap.isOpened():\n",
    "        print(\"âŒ ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        return\n",
    "    \n",
    "    frame_count = 0  # í”„ë ˆì„ ì¹´ìš´í„° ì´ˆê¸°í™”\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()  # í”„ë ˆì„ ì½ê¸°\n",
    "        if not ret:\n",
    "            print(\"â¹ï¸ ì˜ìƒ ìŠ¤íŠ¸ë¦¼ì´ ëë‚¬ê±°ë‚˜, ì˜¤ë¥˜ ë°œìƒ\")\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        # 0.1ì´ˆ(100ms)ë§ˆë‹¤ ì²˜ë¦¬ (30 FPS ê¸°ì¤€, ì•½ 3í”„ë ˆì„ë§ˆë‹¤ 1ë²ˆ)\n",
    "        if frame_count % 3 != 0:\n",
    "            continue\n",
    "\n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")  # í˜„ì¬ íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë¡\n",
    "        \n",
    "        # OpenCVëŠ” BGR, YOLOëŠ” RGB ì‚¬ìš©í•˜ë¯€ë¡œ ë³€í™˜\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # ì›ë³¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥\n",
    "        screenshot_path = os.path.join(screenshot_dir, f\"{timestamp}.jpg\")\n",
    "        cv2.imwrite(screenshot_path, frame)  \n",
    "        print(f\"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {screenshot_path}\")\n",
    "\n",
    "        # ------------------------\n",
    "        # 6. YOLO ëª¨ë¸ ì‹¤í–‰ (ê°œ íƒì§€)\n",
    "        # ------------------------\n",
    "        results = yolo_model(frame_rgb)\n",
    "        best_box = None  # ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ë°”ìš´ë”© ë°•ìŠ¤\n",
    "        best_confidence = 0.0  # ìµœê³  ì‹ ë¢°ë„ ì´ˆê¸°í™”\n",
    "\n",
    "        for result in results:\n",
    "            for box in result.boxes.data:\n",
    "                x1, y1, x2, y2, conf, cls = box.tolist()\n",
    "                \n",
    "                if int(cls) == 16 and conf > best_confidence:  # í´ë˜ìŠ¤ 16ì€ 'dog'\n",
    "                    best_confidence = conf\n",
    "                    best_box = (int(x1), int(y1), int(x2), int(y2))\n",
    "\n",
    "        # ê°œê°€ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ í•´ë‹¹ í”„ë ˆì„ ê±´ë„ˆëœ€\n",
    "        if best_box is None:\n",
    "            #print(f\"â© ê°œê°€ ê°ì§€ë˜ì§€ ì•ŠìŒ (Timestamp: {timestamp})\")\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2 = best_box\n",
    "        print(f\"ğŸ¶ ê°œ ê°ì§€ë¨ (ì¢Œí‘œ: {best_box}, ì‹ ë¢°ë„: {best_confidence:.2f})\")\n",
    "\n",
    "        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦° ì´ë¯¸ì§€ ì €ì¥\n",
    "        bbox_screenshot_path = os.path.join(bbox_screenshot_dir, f\"{timestamp}_bbox.jpg\")\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)  # ë¹¨ê°„ìƒ‰ ì‚¬ê°í˜• ê·¸ë¦¬ê¸°\n",
    "        cv2.imwrite(bbox_screenshot_path, frame)\n",
    "        print(f\"ğŸ“¸ ë°”ìš´ë”© ë°•ìŠ¤ ì´ë¯¸ì§€ ì €ì¥: {bbox_screenshot_path}\")\n",
    "\n",
    "        # ------------------------\n",
    "        # 7. ë°”ìš´ë”© ë°•ìŠ¤ ì´ë¯¸ì§€ ResNetì— ì…ë ¥\n",
    "        # ------------------------\n",
    "        cropped_img = frame_rgb[y1:y2, x1:x2]  # YOLOì—ì„œ íƒì§€ëœ ì˜ì—­ í¬ë¡­\n",
    "        cropped_img_pil = Image.fromarray(cropped_img)  # PIL ì´ë¯¸ì§€ ë³€í™˜\n",
    "        processed_img = transform(cropped_img_pil)  # ì „ì²˜ë¦¬ ì ìš©\n",
    "        processed_img = processed_img.unsqueeze(0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€\n",
    "\n",
    "        # ResNet ëª¨ë¸ë¡œ ë¶„ë¥˜ ìˆ˜í–‰\n",
    "        with torch.no_grad():\n",
    "            outputs = resnet_model(processed_img)\n",
    "            probs = torch.softmax(outputs, dim=1)  # í™•ë¥ ê°’ ê³„ì‚°\n",
    "            predicted_class = torch.argmax(probs, dim=1).item()  # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ í´ë˜ìŠ¤ ì„ íƒ\n",
    "            confidence = probs[0, predicted_class].item()  # í•´ë‹¹ í´ë˜ìŠ¤ì˜ í™•ë¥ ê°’\n",
    "\n",
    "        # ------------------------\n",
    "        # 8. CSV ë¡œê·¸ ì €ì¥\n",
    "        # ------------------------\n",
    "        class_labels = [\n",
    "            \"BODYLOWER\", \"BODYSCRATCH\", \"BODYSHAKE\", \"FEETUP\",\n",
    "            \"FOOTUP\", \"LYING\", \"MOUNTING\", \"SIT\", \"TURN\", \"WALKRUN\"\n",
    "        ]\n",
    "        predicted_label = class_labels[predicted_class]\n",
    "        print(f\"âœ… ì˜ˆì¸¡ëœ í¬ì¦ˆ: {predicted_label} (í™•ë¥ : {confidence:.2f})\")\n",
    "\n",
    "        # 8. CSV ë¡œê·¸ ì €ì¥ (ì¦‰ì‹œ íŒŒì¼ì— ì¶”ê°€)\n",
    "        new_log = pd.DataFrame([[timestamp, best_box, predicted_label]], columns=log_df.columns)\n",
    "        new_log.to_csv(log_csv_path, mode='a', header=not os.path.exists(log_csv_path), index=False)  # âœ… ì¦‰ì‹œ CSV ì €ì¥\n",
    "        print(f\"ğŸ“‚ ì¦‰ì‹œ CSV ì €ì¥ ì™„ë£Œ: {log_csv_path}\")\n",
    "\n",
    "\n",
    "    cap.release()  # ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ í•´ì œ\n",
    "    log_df.to_csv(log_csv_path, index=False)\n",
    "    print(\"ğŸ“‚ CSV ë¡œê·¸ ì €ì¥ ì™„ë£Œ:\", log_csv_path)\n",
    "\n",
    "# ------------------------\n",
    "# 9. ì‹¤í–‰\n",
    "# ------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    process_video()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì•„ë˜ ì½”ë“œëŠ” ì˜ìƒì—ì„œ ì›ë³¸ ìŠ¤í¬ë¦°ìƒ·, BBOX ëœ ìŠ¤í¬ë¦°ìƒ·, log.csv(timestamp, bbox, class), í´ë˜ìŠ¤ ë³€ê²½ì‹œ.MP4ê¹Œì§€ ë§Œë“œëŠ” ì „ì²´ ì½”ë“œì…ë‹ˆë‹¤. ê³ ì¹ ê±° ê³ ì¹˜ê³  ì‚¬ìš©í•˜ë©´ ë ê±° ê°™ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "\n",
    "# ------------------------\n",
    "# 1. í™˜ê²½ ì„¤ì •\n",
    "# ------------------------\n",
    "video_path = \"/Users/vairocana/Downloads/test_video1.mp4\"  # ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ì‚¬ìš© ì‹œ video_path = 0\n",
    "output_dir = \"/Users/vairocana/Downloads/ROGUN\"  # ì €ì¥í•  í´ë”\n",
    "screenshot_dir = os.path.join(output_dir, \"screenshot\")  # ì›ë³¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥ í´ë”\n",
    "bbox_screenshot_dir = os.path.join(output_dir, \"bbox_screenshot\")  # ë°”ìš´ë”© ë°•ìŠ¤ ìŠ¤í¬ë¦°ìƒ· ì €ì¥ í´ë”\n",
    "mp4_output_dir = os.path.join(output_dir, \"mp4\")  # MP4 ì €ì¥ í´ë”\n",
    "log_csv_path = os.path.join(output_dir, \"log.csv\")  # CSV ë¡œê·¸ ê²½ë¡œ\n",
    "\n",
    "# í´ë” ìƒì„± (ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìë™ ìƒì„±)\n",
    "os.makedirs(screenshot_dir, exist_ok=True)\n",
    "os.makedirs(bbox_screenshot_dir, exist_ok=True)\n",
    "os.makedirs(mp4_output_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# CSV ë¡œê·¸ ì´ˆê¸°í™” (ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)\n",
    "columns = [\"timestamp\", \"bbox\", \"class\"]\n",
    "log_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# ------------------------\n",
    "# 2. YOLOv11 ëª¨ë¸ ë¡œë“œ (ê°œ ê°ì²´ íƒì§€)\n",
    "# ------------------------\n",
    "yolo_model = YOLO(\"/Users/vairocana/Downloads/yolo11m.pt\")  # YOLOv11m ì‚¬ìš©\n",
    "print(\"âœ… YOLO ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "\n",
    "# ------------------------\n",
    "# 3. ResNet ëª¨ë¸ ë¡œë“œ (í¬ì¦ˆ ë¶„ë¥˜)\n",
    "# ------------------------\n",
    "resnet_model = models.resnet18(weights=None)  # í•„ìš”ì‹œ resnet50ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥\n",
    "num_features = resnet_model.fc.in_features\n",
    "num_classes = 10  # í˜„ì¬ 10ê°œ í´ë˜ìŠ¤ ì‚¬ìš©. 8ê°œ í´ë˜ìŠ¤ ëª¨ë¸ì´ë©´ ë°”ê¿”ì•¼ í•¨.\n",
    "resnet_model.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "# í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "model_path = \"/Users/vairocana/Desktop/AI/resnet_models/resnet18_model_82.pth\"  # ê²½ë¡œ ìˆ˜ì • í•„ìš”\n",
    "resnet_model.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
    "resnet_model.to(\"cpu\")\n",
    "resnet_model.eval()  # í‰ê°€ ëª¨ë“œ ì„¤ì •\n",
    "print(\"âœ… ResNet ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "\n",
    "# ------------------------\n",
    "# 4. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ (ResNet ì…ë ¥ì— ë§ê²Œ ë³€í™˜)\n",
    "# ------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 224x224 í¬ê¸°ë¡œ ì¡°ì •\n",
    "    transforms.ToTensor(),  # PyTorch í…ì„œ ë³€í™˜\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet ì •ê·œí™”\n",
    "])\n",
    "\n",
    "# ------------------------\n",
    "# 5. MP4 ì €ì¥ í•¨ìˆ˜ (í´ë˜ìŠ¤ ë³€ê²½ ê°ì§€ ì‹œ ì‹¤í–‰)\n",
    "# ------------------------\n",
    "def save_behavior_change_mp4(timestamp, prev_class, new_class):\n",
    "    \"\"\"\n",
    "    í–‰ë™ ë³€í™” ê°ì§€ ì‹œ MP4 ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•˜ì—¬ ì €ì¥í•˜ëŠ” í•¨ìˆ˜\n",
    "    - timestamp: í´ë˜ìŠ¤ ë³€í™”ê°€ ê°ì§€ëœ ì‹œì \n",
    "    - prev_class: ë³€ê²½ ì „ í–‰ë™ í´ë˜ìŠ¤\n",
    "    - new_class: ë³€ê²½ í›„ í–‰ë™ í´ë˜ìŠ¤\n",
    "    \"\"\"\n",
    "    mp4_filename = f\"{prev_class}_TO_{new_class}_{timestamp}.mp4\"\n",
    "    mp4_path = os.path.join(mp4_output_dir, mp4_filename)\n",
    "\n",
    "    # ìŠ¤í¬ë¦°ìƒ· í´ë”ì—ì„œ ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    all_images = sorted(glob.glob(os.path.join(screenshot_dir, \"*.jpg\")))\n",
    "\n",
    "    # í˜„ì¬ timestampì™€ ê°€ì¥ ê°€ê¹Œìš´ ì¸ë±ìŠ¤ ì°¾ê¸°\n",
    "    target_index = None\n",
    "    for i, img_path in enumerate(all_images):\n",
    "        if timestamp in img_path:\n",
    "            target_index = i\n",
    "            break\n",
    "\n",
    "    if target_index is None:\n",
    "        print(f\"âš ï¸ {timestamp} ê¸°ì¤€ìœ¼ë¡œ í”„ë ˆì„ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ!\")\n",
    "        return\n",
    "\n",
    "    # ì´ì „ 50ê°œ + ì´í›„ 50ê°œ â†’ ì´ 100ê°œ í”„ë ˆì„ ì„ íƒ\n",
    "    start_idx = max(0, target_index - 50)\n",
    "    end_idx = min(len(all_images), target_index + 50)\n",
    "    selected_images = all_images[start_idx:end_idx]\n",
    "\n",
    "    if len(selected_images) < 10:  # ìµœì†Œ í”„ë ˆì„ ìˆ˜ ì œí•œ\n",
    "        print(f\"âš ï¸ MP4 ìƒì„± ì‹¤íŒ¨: í”„ë ˆì„ ìˆ˜ ë¶€ì¡± ({len(selected_images)}ê°œ)\")\n",
    "        return\n",
    "\n",
    "    # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë¡œ í•´ìƒë„ í™•ì¸\n",
    "    first_frame = cv2.imread(selected_images[0])\n",
    "    height, width, _ = first_frame.shape\n",
    "\n",
    "    # OpenCV VideoWriter ì„¤ì •\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # MP4 ì½”ë± ì„¤ì •\n",
    "    fps = 10  # ì´ˆë‹¹ 10í”„ë ˆì„ ì„¤ì •\n",
    "    video_writer = cv2.VideoWriter(mp4_path, fourcc, fps, (width, height))\n",
    "\n",
    "    # ì„ íƒëœ ì´ë¯¸ì§€ë“¤ì„ í•˜ë‚˜ì”© ë¹„ë””ì˜¤ í”„ë ˆì„ìœ¼ë¡œ ì¶”ê°€\n",
    "    for img_path in selected_images:\n",
    "        frame = cv2.imread(img_path)\n",
    "        if frame is not None:\n",
    "            video_writer.write(frame)\n",
    "\n",
    "    video_writer.release()\n",
    "    print(f\"ğŸ¥ MP4 ì €ì¥ ì™„ë£Œ: {mp4_path}\")\n",
    "\n",
    "# ------------------------\n",
    "# 6. ì‹¤ì‹œê°„ ì˜ìƒ ì²˜ë¦¬\n",
    "# ------------------------\n",
    "def process_video():\n",
    "    global log_df  # CSV ë¡œê·¸ ë°ì´í„°í”„ë ˆì„\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"âŒ ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "        return\n",
    "    \n",
    "    frame_count = 0  \n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"â¹ï¸ ì˜ìƒ ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ\")\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        \n",
    "        if frame_count % 3 != 0:\n",
    "            continue\n",
    "\n",
    "        timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        \n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        screenshot_path = os.path.join(screenshot_dir, f\"{timestamp}.jpg\")\n",
    "        cv2.imwrite(screenshot_path, frame)  \n",
    "\n",
    "        results = yolo_model(frame_rgb)\n",
    "        best_box, best_confidence = None, 0.0\n",
    "\n",
    "        for result in results:\n",
    "            for box in result.boxes.data:\n",
    "                x1, y1, x2, y2, conf, cls = box.tolist()\n",
    "                \n",
    "                if int(cls) == 16 and conf > best_confidence:\n",
    "                    best_confidence = conf\n",
    "                    best_box = (int(x1), int(y1), int(x2), int(y2))\n",
    "\n",
    "        if best_box is None:\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2 = best_box\n",
    "\n",
    "        bbox_screenshot_path = os.path.join(bbox_screenshot_dir, f\"{timestamp}_bbox.jpg\")\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "        cv2.imwrite(bbox_screenshot_path, frame)\n",
    "\n",
    "        cropped_img = frame_rgb[y1:y2, x1:x2]\n",
    "        cropped_img_pil = Image.fromarray(cropped_img)\n",
    "        processed_img = transform(cropped_img_pil).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = resnet_model(processed_img)\n",
    "            predicted_class = torch.argmax(torch.softmax(outputs, dim=1), dim=1).item()\n",
    "\n",
    "        class_labels = [\"BODYLOWER\", \"BODYSCRATCH\", \"BODYSHAKE\", \"FEETUP\", \"FOOTUP\", \"LYING\", \"MOUNTING\", \"SIT\", \"TURN\", \"WALKRUN\"]\n",
    "        predicted_label = class_labels[predicted_class]\n",
    "\n",
    "        if os.path.exists(log_csv_path):\n",
    "            existing_log = pd.read_csv(log_csv_path)\n",
    "            if len(existing_log) > 0 and existing_log.iloc[-1][\"class\"] != predicted_label:\n",
    "                save_behavior_change_mp4(timestamp, existing_log.iloc[-1][\"class\"], predicted_label)\n",
    "\n",
    "        pd.DataFrame([[timestamp, best_box, predicted_label]], columns=log_df.columns).to_csv(log_csv_path, mode='a', header=not os.path.exists(log_csv_path), index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_video()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì—¬ê¸°ì„œ ë¶€í„° ì „ì— ì‚¬ìš©í•˜ë˜ ê¸°ë³¸ ì½”ë“œ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO v11së¥¼ ì´ìš©í•œ ê°œ ê°ì²´ íƒì§€ í›„ 224x224ë¡œ ë¦¬ì‚¬ì´ì¦ˆí•˜ê³  ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
    "ìšœë¡œëŠ” COCO ë°ì´í„°ì…‹ì˜ 80ê°œì˜ í´ë˜ìŠ¤ë¥¼ ê°€ì§€ê³  ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ì…ë‹ˆë‹¤.\n",
    "80ê°œì˜ í´ë˜ìŠ¤ ì¤‘ì— 16ë²ˆ ì¸ë±ìŠ¤(ìˆ«ìë¡œ ì„¸ë©´ 17ë²ˆì¨°)ì´ ê°œ í´ë˜ìŠ¤ì¸ë° ì¶œì²˜ì— ë”°ë¼ ì¸ë±ìŠ¤ 17ì´ë¼ê³  ì¡°ê¸ˆ ë‹¤ë¥´ê²Œ ë‚˜ì˜µë‹ˆë‹¤.\n",
    "ì¼ë‹¨ ì‘ë™í•´ì„œ 16ìœ¼ë¡œ ë‘ì—ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… YOLOv11 ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "Using device: mps\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([10, 512]) from checkpoint, the shape in current model is torch.Size([8, 512]).\n\tsize mismatch for fc.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([8]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m  \u001b[38;5;66;03m# í´ë˜ìŠ¤ ê°œìˆ˜ (ë°ì´í„°ì…‹ì— ë§ê²Œ ìˆ˜ì •)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(num_features, num_classes)\n\u001b[0;32m---> 31\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# í‰ê°€ ëª¨ë“œë¡œ ì „í™˜ (Dropout, BatchNorm ë“± ë¹„í™œì„±í™”)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/AI/ai/lib/python3.9/site-packages/torch/nn/modules/module.py:2581\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2573\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2574\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2575\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2576\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2577\u001b[0m             ),\n\u001b[1;32m   2578\u001b[0m         )\n\u001b[1;32m   2580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2581\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2583\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2584\u001b[0m         )\n\u001b[1;32m   2585\u001b[0m     )\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([10, 512]) from checkpoint, the shape in current model is torch.Size([8, 512]).\n\tsize mismatch for fc.bias: copying a param with shape torch.Size([10]) from checkpoint, the shape in current model is torch.Size([8])."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ëª¨ë¸, ìšœë¡œ, ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì •ë§Œ í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.\n",
    "# ------------------------\n",
    "# 1. YOLOv11 ëª¨ë¸ ë¡œë“œ (ê°œ ê°ì²´ íƒì§€ìš©)\n",
    "# ------------------------\n",
    "# YOLOv11s ëª¨ë¸ì€ COCO ë°ì´í„°ì…‹ìœ¼ë¡œ ì‚¬ì „ í•™ìŠµë˜ì–´ ìˆìœ¼ë¯€ë¡œ, 'dog' í´ë˜ìŠ¤(ì¼ë°˜ì ìœ¼ë¡œ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ 16)ë¥¼ ì¸ì‹í•©ë‹ˆë‹¤.\n",
    "yolo_model_path = \"/Users/vairocana/Downloads/yolo11m.pt\"  # YOLOv11m ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (í•´ë‹¹ íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•¨)\n",
    "yolo_model = YOLO(yolo_model_path)\n",
    "print(\"âœ… YOLOv11 ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# ------------------------\n",
    "# 2. ResNet ëª¨ë¸ ë¡œë“œ (ë¶„ë¥˜ìš©)\n",
    "# ------------------------\n",
    "model_path = \"/Users/vairocana/Desktop/AI/resnet_models/resnet18_model_82.pth\"  # ì €ì¥ëœ ResNet50 ëª¨ë¸ íŒŒì¼ ê²½ë¡œ\n",
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# ResNet50 ëª¨ë¸ì„ ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ ì—†ì´ ìƒì„±í•œ í›„, ë§ˆì§€ë§‰ fc ë ˆì´ì–´ë¥¼ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ìˆ˜ì— ë§ê²Œ ìˆ˜ì •\n",
    "model = models.resnet18(weights=None)\n",
    "num_features = model.fc.in_features\n",
    "num_classes = 10  # í´ë˜ìŠ¤ ê°œìˆ˜ (ë°ì´í„°ì…‹ì— ë§ê²Œ ìˆ˜ì •)\n",
    "model.fc = nn.Linear(num_features, num_classes)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì „í™˜ (Dropout, BatchNorm ë“± ë¹„í™œì„±í™”)\n",
    "print(\"âœ… ResNetëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# ------------------------\n",
    "# 3. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜ (224Ã—224, ì •ê·œí™”)\n",
    "# ------------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # í¬ë¡­ëœ ì´ë¯¸ì§€ë¥¼ 224Ã—224ë¡œ ì¡°ì •\n",
    "    transforms.ToTensor(),  # í…ì„œ ë³€í™˜\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # ImageNet ì •ê·œí™”\n",
    "])\n",
    "\n",
    "# ------------------------\n",
    "# 4. YOLOë¥¼ ì´ìš©í•˜ì—¬ \"dog\" ê°ì²´ë¥¼ íƒì§€í•˜ê³  í¬ë¡­í•˜ëŠ” í•¨ìˆ˜\n",
    "# ------------------------\n",
    "def detect_and_crop(image_path):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ ì´ë¯¸ì§€ ê²½ë¡œì—ì„œ YOLOv8ì„ ì´ìš©í•´ 'dog' ê°ì²´(í´ë˜ìŠ¤ ì¸ë±ìŠ¤ 16)ë¥¼ íƒì§€í•˜ê³ ,\n",
    "    í•´ë‹¹ ë°”ìš´ë”© ë°•ìŠ¤ ì˜ì—­ì„ í¬ë¡­í•œ í›„ 224Ã—224ë¡œ ì „ì²˜ë¦¬í•œ ì´ë¯¸ì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # ì´ë¯¸ì§€ ë¡œë“œ ë° BGR -> RGB ë³€í™˜ (YOLOëŠ” RGB ì‚¬ìš©)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}\")\n",
    "        return None\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # YOLO ì¶”ë¡  ìˆ˜í–‰\n",
    "    results = yolo_model(image_rgb)\n",
    "\n",
    "    # ë””ë²„ê·¸: íƒì§€ëœ ëª¨ë“  ê°ì²´ ì •ë³´ ì¶œë ¥ì¸ë° ê°œ ê°ì²´ë§Œ ì¶œë ¥í•˜ë ¤ë©´\n",
    "    print(\"ğŸ” ê²€ì¶œëœ ê°ì²´ë“¤:\")\n",
    "    for result in results:\n",
    "        for box in result.boxes.data:\n",
    "            # YOLOv11 ê²°ê³¼ tensorë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ [x1, y1, x2, y2, confidence, class] ìˆœì„œë¡œ ì–»ìŒ\n",
    "            box_vals = box.tolist()\n",
    "            x1, y1, x2, y2, conf, cls = box_vals\n",
    "            print(f\"  í´ë˜ìŠ¤: {int(cls)}, ì‹ ë¢°ë„: {conf:.2f}\")\n",
    "\n",
    "    # 'dog' ê°ì²´ ì¶”ì¶œ (COCO ê¸°ì¤€ dog í´ë˜ìŠ¤ ì¸ë±ìŠ¤ëŠ” ì¼ë°˜ì ìœ¼ë¡œ 16)\n",
    "    found_dog = False\n",
    "    for result in results:\n",
    "        for box in result.boxes.data:\n",
    "            box_vals = box.tolist()\n",
    "            x1, y1, x2, y2, conf, cls = box_vals\n",
    "            # ì—¬ê¸°ì„œ dog í´ë˜ìŠ¤ ì¡°ê±´: í´ë˜ìŠ¤ ì¸ë±ìŠ¤ 16, ì‹ ë¢°ë„ 0.4 ì´ìƒ (í•„ìš”ì— ë”°ë¼ ì¡°ì •)\n",
    "            if int(cls) == 16 and conf > 0.4:\n",
    "                found_dog = True\n",
    "                # ì¢Œí‘œ ì •ìˆ˜í˜• ë³€í™˜\n",
    "                x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "                # ê°œ ê°ì²´ ì˜ì—­ í¬ë¡­ (RGB ì´ë¯¸ì§€ ê¸°ì¤€)\n",
    "                cropped_img = image_rgb[y1:y2, x1:x2]\n",
    "                # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜\n",
    "                cropped_img_pil = Image.fromarray(cropped_img)\n",
    "                # ì „ì²˜ë¦¬: 224Ã—224 ë¦¬ì‚¬ì´ì¦ˆ ë° ì •ê·œí™”, ë°°ì¹˜ ì°¨ì› ì¶”ê°€\n",
    "                processed_img = transform(cropped_img_pil)\n",
    "                processed_img = processed_img.unsqueeze(0)\n",
    "                return processed_img.to(device)\n",
    "    if not found_dog:\n",
    "        print(\"âš ï¸ ì´ë¯¸ì§€ì—ì„œ ê°œ ê°ì²´ë¥¼ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!\")\n",
    "    return None\n",
    "\n",
    "# ------------------------\n",
    "# 5. ResNetì„ ì´ìš©í•˜ì—¬ í¬ì¦ˆ(í´ë˜ìŠ¤) ë¶„ë¥˜í•˜ëŠ” í•¨ìˆ˜\n",
    "# ------------------------\n",
    "def classify_pose(image_path):\n",
    "    \"\"\"\n",
    "    YOLOë¥¼ ì‚¬ìš©í•´ ì£¼ì–´ì§„ ì´ë¯¸ì§€ì—ì„œ ê°œ ê°ì²´ë¥¼ íƒì§€í•˜ì—¬ í¬ë¡­í•œ í›„,\n",
    "    ResNet ëª¨ë¸ë¡œ ë¶„ë¥˜í•˜ì—¬ í¬ì¦ˆ(í´ë˜ìŠ¤)ë¥¼ ì˜ˆì¸¡í•˜ëŠ” í•¨ìˆ˜.\n",
    "    \"\"\"\n",
    "    cropped_image = detect_and_crop(image_path)\n",
    "    if cropped_image is None:\n",
    "        print(\"âŒ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ê°œ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    # ResNet50ì„ ì´ìš©í•œ ì˜ˆì¸¡ (gradient ê³„ì‚° ë¹„í™œì„±í™”)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(cropped_image)\n",
    "        _, predicted_class = outputs.max(1)\n",
    "\n",
    "    # í´ë˜ìŠ¤ ë¼ë²¨ (ë°ì´í„°ì…‹ì— ë§ê²Œ ìˆ˜ì •)\n",
    "    class_labels = [\n",
    "        \"BODYLOWER\", \"BODYSCRATCH\", \"BODYSHAKE\", \"FEETUP\", \n",
    "        \"FOOTUP\", \"LYING\", \"MOUNTING\", \"SIT\", \"TURN\", \"WALKRUN\"\n",
    "    ]\n",
    "    predicted_label = class_labels[predicted_class.item()]\n",
    "    print(f\"âœ… ì˜ˆì¸¡ëœ í¬ì¦ˆ: {predicted_label}\")\n",
    "\n",
    "# ------------------------\n",
    "# 6. ì‹¤í–‰: ë‹¨ì¼ ì´ë¯¸ì§€ì— ëŒ€í•´ YOLOë¡œ ê°œ ê°ì²´ íƒì§€ í›„, ResNetìœ¼ë¡œ ë¶„ë¥˜\n",
    "# ------------------------\n",
    "image_path = \"/Users/vairocana/Downloads/sample7.jpeg\"  # í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œ (ìˆ˜ì • í•„ìš”)\n",
    "classify_pose(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ìšœë¡œë¡œ í¬ë¡­ëœ ì´ë¯¸ì§€ í™•ì¸ì„ ìœ„í•œ ì½”ë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… YOLOv11 ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "\n",
      "0: 640x512 2 dogs, 1 skis, 46.3ms\n",
      "Speed: 1.3ms preprocess, 46.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "ğŸ” ê²€ì¶œëœ ê°ì²´ë“¤:\n",
      "  í´ë˜ìŠ¤: 16, ì‹ ë¢°ë„: 0.81\n",
      "  í´ë˜ìŠ¤: 16, ì‹ ë¢°ë„: 0.36\n",
      "  í´ë˜ìŠ¤: 30, ì‹ ë¢°ë„: 0.33\n",
      "âœ… ê°œ ê°ì²´ë¥¼ ê²€ì¶œí•˜ì—¬ í¬ë¡­í–ˆìŠµë‹ˆë‹¤! ì €ì¥ ê²½ë¡œ: /Users/vairocana/Downloads//cropped_dog.jpg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "#ìšœë¡œì™€ ì´ë¯¸ì§€ ê²½ë¡œë§Œ ìˆ˜ì •í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.\n",
    "# ------------------------\n",
    "# 1. YOLOv11 ëª¨ë¸ ë¡œë“œ \n",
    "# ------------------------\n",
    "yolo_model_path = \"/Users/vairocana/Downloads/yolo11s.pt\"  # YOLOv11s ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (í•´ë‹¹ íŒŒì¼ì´ ì¡´ì¬í•´ì•¼ í•¨)\n",
    "yolo_model = YOLO(yolo_model_path)\n",
    "print(\"âœ… YOLOv11 ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# ------------------------\n",
    "# 2. ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì • (í•„ìš”ì— ë”°ë¼ ìˆ˜ì •)\n",
    "# ------------------------\n",
    "image_path = \"/Users/vairocana/Downloads/coco_sample2.jpg\"\n",
    "output_path = \"/Users/vairocana/Downloads//cropped_dog.jpg\"\n",
    "\n",
    "# ------------------------\n",
    "# 3. ì´ë¯¸ì§€ ë¡œë“œ ë° YOLO ì¶”ë¡  ìˆ˜í–‰\n",
    "# ------------------------\n",
    "image = cv2.imread(image_path)\n",
    "if image is None:\n",
    "    print(f\"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}\")\n",
    "    exit()\n",
    "\n",
    "# OpenCVëŠ” BGR, YOLOëŠ” RGBì´ë¯€ë¡œ ë³€í™˜\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "results = yolo_model(image_rgb)  # YOLO ì¶”ë¡  ìˆ˜í–‰\n",
    "\n",
    "# ------------------------\n",
    "# 4. ë””ë²„ê¹…: ê²€ì¶œëœ ëª¨ë“  ê°ì²´ ì •ë³´ ì¶œë ¥\n",
    "# ------------------------\n",
    "print(\"ğŸ” ê²€ì¶œëœ ê°ì²´ë“¤:\")\n",
    "for result in results:\n",
    "    # result.boxes.dataëŠ” ê° ë°•ìŠ¤ì— ëŒ€í•´ [x1, y1, x2, y2, confidence, class]ë¥¼ í¬í•¨í•˜ëŠ” tensorì…ë‹ˆë‹¤.\n",
    "    for box in result.boxes.data:\n",
    "        # í…ì„œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ ì¸ë±ìŠ¤ë¡œ ì ‘ê·¼\n",
    "        box = box.tolist()\n",
    "        x1, y1, x2, y2, conf, cls = box\n",
    "        print(f\"  í´ë˜ìŠ¤: {int(cls)}, ì‹ ë¢°ë„: {conf:.2f}\")\n",
    "\n",
    "# ------------------------\n",
    "# 5. \"dog\" í´ë˜ìŠ¤ (COCO ê¸°ì¤€ dogì˜ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ëŠ” 16ì´ë¼ê³  ë‚˜ì˜¨ê³³ë„ ìˆê³  17ë„ ìˆìŒ..)ë§Œ ì¶”ì¶œí•˜ì—¬ í¬ë¡­\n",
    "# ------------------------\n",
    "found_dog = False\n",
    "for result in results:\n",
    "    for box in result.boxes.data:\n",
    "        box = box.tolist()\n",
    "        x1, y1, x2, y2, conf, cls = box\n",
    "        if int(cls) == 16 and conf > 0.4:  # dog í´ë˜ìŠ¤ ì¸ë±ìŠ¤ê°€ 16 ì•„ë‹ˆë©´ 17ì¸ë° ì°¾ì•„ë„ ë‘˜ë‹¤ ë‚˜ì™€ì„œ ì¼ë‹¨ 16ìœ¼ë¡œ ì„¤ì •. ì¡°ê±´ (ì‹ ë¢°ë„ 0.4 ì´ìƒ)\n",
    "            found_dog = True\n",
    "            # ì¢Œí‘œ ì •ìˆ˜í˜• ë³€í™˜\n",
    "            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])\n",
    "            # ê°œ ê°ì²´ ì˜ì—­ í¬ë¡­ (RGB ì´ë¯¸ì§€ ê¸°ì¤€)\n",
    "            cropped_dog = image_rgb[y1:y2, x1:x2]\n",
    "            # PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜ í›„ ì €ì¥ (JPEG í’ˆì§ˆ 95)\n",
    "            cropped_img_pil = Image.fromarray(cropped_dog)\n",
    "            cropped_img_pil.save(output_path, quality=95)\n",
    "            print(f\"âœ… ê°œ ê°ì²´ë¥¼ ê²€ì¶œí•˜ì—¬ í¬ë¡­í–ˆìŠµë‹ˆë‹¤! ì €ì¥ ê²½ë¡œ: {output_path}\")\n",
    "            break  # í•˜ë‚˜ì˜ ê°œë§Œ ì²˜ë¦¬\n",
    "    if found_dog:\n",
    "        break\n",
    "\n",
    "if not found_dog:\n",
    "    print(\"âŒ ì´ë¯¸ì§€ì—ì„œ ê°œ ê°ì²´ë¥¼ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
